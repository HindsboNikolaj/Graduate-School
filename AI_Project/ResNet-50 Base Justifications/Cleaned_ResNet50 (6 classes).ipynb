{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"id":"mnJmsV0thpSW","executionInfo":{"status":"ok","timestamp":1712166376357,"user_tz":240,"elapsed":151,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","from PIL import Image\n","from tempfile import TemporaryDirectory\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from tqdm import tqdm\n","from torchvision.io import read_image\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive') # Mounts it to YOUR drive. Nishanth and Chad, you will have to add a shortcut to dataset-resized.\n","# Dataset-realized is in the folder that was shared.\n","import os\n","\n","# Path to the dataset folder\n","folder_path = '/content/drive/My Drive/dataset-resized' # All images are 512 x 384\n","#folder_path = '/content/drive/My Drive/24-782: ML and AI for Engineers - Project/4- Code/dataset-resized'  #Chad path\n","# folder_path = '/content/drive/My Drive/Courses/24-782: ML and AI for Engineers - Project/4- Code/dataset-resized' #Nishanth"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCRu-65Bh1V9","executionInfo":{"status":"ok","timestamp":1712166377710,"user_tz":240,"elapsed":1218,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}},"outputId":"a3aa633c-ce4b-42a1-e5b5-86f5ac4c738b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["#Get the paths/labels. This one includes an excpetion incase one fails.\n","def prepare_data(data_dir):\n","    categories = ['Trash', 'Plastic', 'Paper', 'Metal', 'Glass', 'Cardboard']\n","    image_paths = []\n","    labels = []  # Numerical labels: 0 for Trash, 1 for Plastic, etc.\n","\n","    for label, category in enumerate(categories):\n","        category_dir = os.path.join(data_dir, category)\n","        try:\n","            for file in os.listdir(category_dir):\n","                if file.endswith('.jpg') or file.endswith('.png'):\n","                    image_paths.append(os.path.join(category_dir, file))\n","                    labels.append(label)\n","        except Exception as e:\n","            print(f\"Failed to process category {category}: {e}\")\n","            continue\n","\n","    return image_paths, labels"],"metadata":{"id":"OOcdsXZRh1YA","executionInfo":{"status":"ok","timestamp":1712166377711,"user_tz":240,"elapsed":8,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["image_paths, labels = prepare_data(folder_path)"],"metadata":{"id":"K5hLwH57h1Z0","executionInfo":{"status":"ok","timestamp":1712166382839,"user_tz":240,"elapsed":5133,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# class CustomDataset(Dataset):\n","#     def __init__(self, image_paths, labels, transform=None):\n","#         self.image_paths = image_paths\n","#         self.labels = labels\n","#         self.transform = transform\n","\n","#     def __len__(self):\n","#         return len(self.image_paths)\n","\n","#     def __getitem__(self, index):\n","#         image_path = self.image_paths[index]\n","#         image = read_image(image_path)  # This loads image as a tensor in [0,1]\n","\n","#         if self.transform:\n","#             image = self.transform(image)\n","\n","#         label = torch.tensor(self.labels[index], dtype=torch.long)\n","#         return image, label"],"metadata":{"id":"tse67Awfh1bp","executionInfo":{"status":"ok","timestamp":1712166382840,"user_tz":240,"elapsed":16,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, image_paths, labels, transform=None):\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, index):\n","        image_path = self.image_paths[index]\n","        # Load the image as a PIL Image\n","        image = Image.open(image_path).convert(\"RGB\")\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        label = torch.tensor(self.labels[index], dtype=torch.long)\n","        return image, label\n"],"metadata":{"id":"TvzyYS9ilC_Q","executionInfo":{"status":"ok","timestamp":1712166382840,"user_tz":240,"elapsed":14,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["train_paths, test_paths, train_labels, test_labels = train_test_split(\n","    image_paths, labels, test_size=0.15, random_state=0, stratify=labels) #This time we split the oringinal to train/test, so we use the stratify=labels\n","\n","train_paths, val_paths, train_labels, val_labels = train_test_split(\n","    train_paths, train_labels, test_size=0.175, random_state=0, stratify=train_labels) #This time we further split train to include validation, so stratify=trian_labels"],"metadata":{"id":"lN3SApsTh1f1","executionInfo":{"status":"ok","timestamp":1712166382840,"user_tz":240,"elapsed":13,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["#I corrected the Normalization and cleaned the transforms we are note using.\n","\n","#transforms.RandomCrop(224),\n","\n","training_transform = transforms.Compose([\n","    transforms.Resize(256, antialias=True),\n","    transforms.RandomCrop(224),\n","    transforms.RandomRotation(20),\n","    transforms.RandomHorizontalFlip(0.1),\n","    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n","    transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","transform = transforms.Compose([\n","    transforms.Resize(256, antialias=True),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n"],"metadata":{"id":"eawRa0Uah1h4","executionInfo":{"status":"ok","timestamp":1712166382840,"user_tz":240,"elapsed":12,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["#This will use the images and labels and apply to transforms for each dataset.\n","train_dataset = CustomDataset(train_paths, train_labels, transform=training_transform)\n","val_dataset = CustomDataset(val_paths, val_labels, transform=transform)\n","test_dataset = CustomDataset(test_paths, test_labels, transform=transform)"],"metadata":{"id":"KvAGJhUVh1jv","executionInfo":{"status":"ok","timestamp":1712166382841,"user_tz":240,"elapsed":12,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["#Dataloaders created\n","\n","batch_size = 32\n","\n","train_dataloader = DataLoader(train_dataset, batch_size = batch_size, num_workers=1, shuffle = True)\n","val_dataloader = DataLoader(val_dataset, batch_size = batch_size, num_workers=1, shuffle = True)\n","test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers=1, shuffle = True)"],"metadata":{"id":"zzM8TvAHh1lz","executionInfo":{"status":"ok","timestamp":1712166383013,"user_tz":240,"elapsed":184,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["#model Resnet50\n","model = torchvision.models.resnet50(weights = 'IMAGENET1K_V1')\n","for param in model.parameters():\n","  param.requires_grad = False\n","\n","in_feat = model.fc.in_features # 2048 input features\n","classes = 6 # output feature classes.\n","\n","model.fc = nn.Sequential(\n","    nn.Linear(in_feat, 512),\n","    nn.ReLU(),\n","    nn.Linear(512, classes)\n",")\n"],"metadata":{"id":"0ELWcWwSiHrN","executionInfo":{"status":"ok","timestamp":1712166384637,"user_tz":240,"elapsed":1626,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3bcc1412-ce9d-4ea9-bf0a-0fc50d76000b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 152MB/s]\n"]}]},{"cell_type":"code","source":["model"],"metadata":{"id":"EYIh7znpiHth","executionInfo":{"status":"ok","timestamp":1712166384637,"user_tz":240,"elapsed":17,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"736d8209-0082-4605-9260-93ac8be8e228"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (0): Linear(in_features=2048, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=6, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["print(in_feat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cy71Rr5yiHvW","executionInfo":{"status":"ok","timestamp":1712166384637,"user_tz":240,"elapsed":13,"user":{"displayName":"Nikolaj Hindsbo","userId":"04640421773336581471"}},"outputId":"ae959184-fd48-4ded-c536-0e416006ce7f"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["2048\n"]}]},{"cell_type":"code","source":["# Training\n","lr = 1e-5\n","step_size = 20\n","gamma = 0.9\n","N_epochs = 5\n","\n","loss_fun = nn.CrossEntropyLoss() #for Mulit Classification\n","optimizer = optim.Adam(params= model.parameters(), lr = lr)\n","lr_schedule = lr_scheduler.StepLR(optimizer= optimizer, step_size = step_size, gamma = gamma)\n","\n","training_losses = []\n","training_acces = []\n","val_losses = []\n","val_acces = []\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","loss_fun.to(device)  # If your loss function has parameters that need to be on a specific device\n","\n","for epoch in tqdm(range(N_epochs)):\n","    train_loss = 0.0\n","    train_acc = 0.0\n","    model.train()\n","\n","    for x, y in train_dataloader:\n","        x, y = x.to(device), y.to(device)\n","\n","        pred = model(x)\n","        _, predicted_classes = torch.max(pred, 1)\n","        correct_predictions = (predicted_classes == y).float()\n","\n","        loss = loss_fun(pred, y.long())\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        train_acc += correct_predictions.sum().item() / y.size(0)\n","\n","\n","    # Average loss and accuracy for the epoch\n","    train_loss /= len(train_dataloader)\n","    train_acc /= len(train_dataloader)\n","    training_losses.append(train_loss)\n","    training_acces.append(train_acc)\n","\n","    # Validation phase\n","    val_loss = 0.0\n","    val_acc = 0.0\n","    model.eval()\n","    with torch.no_grad():\n","        for x, y in val_dataloader:\n","            x, y = x.to(device), y.to(device)\n","\n","            pred = model(x)\n","            _, predicted_classes = torch.max(pred, 1)\n","            correct_predictions = (predicted_classes == y).float()\n","\n","            loss = loss_fun(pred, y.long())  # Ensure consistent data type\n","            val_loss += loss.item()\n","            val_acc += correct_predictions.sum().item() / y.size(0)\n","\n","    val_loss /= len(val_dataloader)\n","    val_acc /= len(val_dataloader)\n","    val_losses.append(val_loss)\n","    val_acces.append(val_acc)\n","    lr_schedule.step()  # Move this outside the batch loop, so it updates per epoch\n","\n","    print(f\"Epoch {epoch+1}/{N_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Z3HE768iHzQ","outputId":"ef273f5d-a30a-4c37-fe27-4f08915a4ad8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/5 [00:00<?, ?it/s]"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)  # Ensure model is on the correct device\n","model.eval()  # Set the model to evaluation mode\n","\n","test_acc = 0\n","test_loss = 0\n","with torch.no_grad():  # No gradients needed for the testing phase\n","    for x, y in test_dataloader:\n","        x, y = x.to(device), y.to(device)  # Move data to the same device as the model\n","\n","        pred = model(x)\n","        _, predicted_classes = torch.max(pred, 1)\n","        correct_predictions = (predicted_classes == y).float()  # Compare predicted classes to true labels\n","        loss = loss_fun(pred, y.long())  # Ensure y is the correct type if necessary\n","\n","        test_loss += loss.item()\n","        accuracy = correct_predictions.sum() / len(y)\n","        test_acc += accuracy.item()\n","\n","test_loss /= len(test_dataloader)\n","test_acc /= len(test_dataloader)\n","\n","print(f\"Test Loss: {test_loss:.4f}\")\n","print(f\"Test Accuracy: {test_acc:.4f}\")"],"metadata":{"id":"hp3qN_4uiH1l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = np.arange(1, N_epochs + 1)\n","\n","# Similar colors for losses\n","color_loss = 'blue'\n","color_val_loss = 'orange'\n","\n","# Similar colors for accuracies\n","color_acc = 'green'\n","color_val_acc = 'red'\n","\n","# Creating the plot with the updated color scheme\n","fig, ax1 = plt.subplots()\n","\n","ax1.set_xlabel('Epoch')\n","ax1.set_ylabel('Loss', color=color_loss)\n","ax1.plot(epochs, training_losses, label='Training Loss', marker='o', color=color_loss)\n","ax1.plot(epochs, val_losses, label='Validation Loss', marker='x', color=color_val_loss)\n","ax1.tick_params(axis='y', labelcolor=color_loss)\n","\n","ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n","\n","ax2.set_ylabel('Accuracy', color=color_acc)\n","ax2.plot(epochs, training_acces, label='Training Accuracy', marker='o', color=color_acc)\n","ax2.plot(epochs, val_acces, label='Validation Accuracy', marker='x', color=color_val_acc)\n","ax2.tick_params(axis='y', labelcolor=color_acc)\n","\n","# Adding legends\n","ax1.legend(loc='upper left')\n","ax2.legend(loc='lower left')\n","\n","fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","plt.title('Training & Validation Loss and Accuracy')\n","plt.show()"],"metadata":{"id":"txq3K5FziX0B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"O0hCNcitEHSj"},"execution_count":null,"outputs":[]}]}